# llm_lecture_2024
大規模言語モデル2024講座の最終課題に関連するリポジトリ

以下のモデルを動かすためのリポジトリです。
GPUはT5でも動くはずですが、推論速度、GPUメモリーの余裕が気になる方はL4で実行してください。

# Huggingface URL
以下の二種類に対応しています。model_idのところで設定してください。
ikedachin/llm-jp-3-13b-october-news-e1-all-3-5-sft-Ozaki-Magpie-20000-sorted-params
https://huggingface.co/ikedachin/llm-jp-3-13b-october-news-e1-all-3-5-sft-llmjp-magpie-20000
